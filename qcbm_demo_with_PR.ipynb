{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:59:28.227620800Z",
     "start_time": "2024-01-25T15:59:25.272555100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import perceval as pcvl\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from src.models import QCBM\n",
    "from src.helpers import ParametrizedQuantumCircuit\n",
    "from src.helpers.utils import gaussian_mixture_pdf, kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of the numerical experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined the initial state, whether we have photon number resolving (PNR) detectors, and the structure of the ansatz (number of variational blocks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:59:30.793360300Z",
     "start_time": "2024-01-25T15:59:30.782146700Z"
    }
   },
   "outputs": [],
   "source": [
    "# input config\n",
    "input_state = pcvl.BasicState(\"|0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0>\")\n",
    "pnr = False\n",
    "#arch = [\"var\", \"var\"]\n",
    "arch = [\"var\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the number of trainings we will average on, the number of iterations per training, and the number of optimization steps. We also define the initial amount of samples (i.e. photons) injected into the QCBM, and the loss parameter $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T15:59:32.939781900Z",
     "start_time": "2024-01-25T15:59:32.933993Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimization config\n",
    "run_count = 20\n",
    "it_count = 100\n",
    "opt_steps = 1000\n",
    "\n",
    "sample_count = 200000\n",
    "loss_parameter = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the first QCBM of this notebook: a lossy scenario where photon recycling is applied.\n",
    "\n",
    "Further parameters about the ansatz, such as one_param_per_interferometer, can also be defined. We refer to the QCBM class for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-25T15:59:34.987153Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "pqc = ParametrizedQuantumCircuit(input_state.m, arch, same_params_in_var=False, one_param_per_interferometer=False)\n",
    "bm_lossy = QCBM(parametrized_circuit=pqc, input_state=input_state, sample_count=sample_count, loss_parameter=loss_parameter, pnr=pnr, \n",
    "                use_samples_only = False, use_photon_recycling=True, miti=True, threshold_stats = True)\n",
    "\n",
    "# get bin count of the distribution based on the output of the circuit\n",
    "bin_count = bm_lossy.bin_count\n",
    "print(bin_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the target distribution and the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pdf_name = 'gaussian_mixture'\n",
    "target_pdf = gaussian_mixture_pdf(bin_count)\n",
    "target_space = np.arange(bin_count)\n",
    "\n",
    "loss_name = 'kl'\n",
    "loss_fun = kl_divergence()\n",
    "#loss_fun = RBFMMD2(sigma_list=[0.25, 4.], basis = np.arange(bin_count))\n",
    "#loss_fun = mmd_rbf(gamma = 0.25)\n",
    "#loss_fun = tvd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign this information to the QCBM.\n",
    "\n",
    "In the case of using samples only in the loss function evaluation, use the commented lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossy.target_pdf = target_pdf\n",
    "bm_lossy.loss_fun = loss_fun\n",
    "bm_lossy.target_space = target_space\n",
    "\n",
    "# if using samples only\n",
    "#target_samples = sample_from_target_pdf(target_space, bm_lossy.sample_count, target_pdf)\n",
    "#bm_lossy.target_samples = target_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a couple of checks about the target probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(target_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lossy, with photon recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start the training of this first QCBM (lossy, with photon recycling applied).\n",
    "\n",
    "First, we have the option to use initialization parameters that were saved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load init parameters - if reusing saved parameters\n",
    "path_init = ''\n",
    "has_init_params_runs = False\n",
    "if os.path.exists(path_init):\n",
    "    has_init_params_runs = True\n",
    "    init_df = pd.read_csv(path_init)\n",
    "    init_params_runs = init_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossy.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossy_loss_runs = np.zeros((run_count, it_count))\n",
    "lossy_tvd_runs = np.zeros((run_count, it_count))\n",
    "lossy_mmd_runs = np.zeros((run_count, it_count))\n",
    "lossy_js_runs = np.zeros((run_count, it_count))\n",
    "lossy_params_runs = np.zeros((run_count, len(bm_lossy.pqc.var_param_map)))\n",
    "\n",
    "# If we wish to save the init parameters\n",
    "if not has_init_params_runs:\n",
    "    init_params_runs = []\n",
    "\n",
    "# Set counter\n",
    "i = 0\n",
    "\n",
    "while i < run_count:\n",
    "    if has_init_params_runs:\n",
    "        init_params_lossy = init_params_runs[i]\n",
    "        bm_lossy.pqc.init_params(red_factor = 1, init_var_params = init_params_lossy)\n",
    "    else:\n",
    "        init_params_lossy = bm_lossy.pqc.init_params()\n",
    "    \n",
    "    print('Initialization OK')\n",
    "    \n",
    "    try:\n",
    "        loss_progress, params_progress, metric_tvd, metric_mmd, metric_js = bm_lossy.fit(opt_steps, it_count, silent=True)\n",
    "        lossy_loss_runs[i, :] = loss_progress\n",
    "        lossy_params_runs[i, :] = params_progress[-1]\n",
    "        \n",
    "        # Extra metrics saved for evaluation of the models:\n",
    "        lossy_tvd_runs[i, :] = metric_tvd\n",
    "        lossy_mmd_runs[i, :] = metric_mmd\n",
    "        lossy_js_runs[i, :] = metric_js\n",
    "        \n",
    "        print('Training instance OK')\n",
    "        i += 1\n",
    "        \n",
    "        # If we wish to save the init parameters\n",
    "        init_params_runs.append(init_params_lossy)\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lossy, without photon recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train a lossy QCBM without photon recycling.\n",
    "\n",
    "We define it, and assign to it the same target distribution and same loss function as the first QCBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossy_noPR = QCBM(parametrized_circuit=pqc, input_state=input_state, sample_count=sample_count, loss_parameter=loss_parameter, pnr=pnr, \n",
    "                     use_samples_only = False, use_photon_recycling=True, miti=False, threshold_stats = True)\n",
    "\n",
    "bm_lossy_noPR.target_pdf = target_pdf\n",
    "bm_lossy_noPR.loss_fun = loss_fun\n",
    "bm_lossy_noPR.target_space = target_space\n",
    "\n",
    "# If using samples only:\n",
    "#bm_lossless.target_samples = target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossy_noPR.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossynoPR_loss_runs = np.zeros((run_count, it_count))\n",
    "lossynoPR_tvd_runs = np.zeros((run_count, it_count))\n",
    "lossynoPR_mmd_runs = np.zeros((run_count, it_count))\n",
    "lossynoPR_js_runs = np.zeros((run_count, it_count))\n",
    "lossynoPR_params_runs = np.zeros((run_count, len(bm_lossy_noPR.pqc.var_param_map)))\n",
    "\n",
    "# Set counter\n",
    "i = 0\n",
    "\n",
    "while i < run_count:\n",
    "    # If using saved init parameters:\n",
    "    init_params_lossy = init_params_runs[i]\n",
    "    bm_lossy_noPR.pqc.init_params(red_factor = 1, init_var_params = init_params_lossy)\n",
    "    \n",
    "    # If not:\n",
    "    #bm_lossless.pqc.init_params()\n",
    "    \n",
    "    print('Initialization OK')\n",
    "    \n",
    "    try:\n",
    "        loss_progress, params_progress, metric_tvd, metric_mmd, metric_js = bm_lossy_noPR.fit(opt_steps, it_count, silent=True)\n",
    "        lossynoPR_loss_runs[i, :] = loss_progress\n",
    "        lossynoPR_params_runs[i, :] = params_progress[-1]\n",
    "        \n",
    "        # Extra metrics saved for evaluation of the models:\n",
    "        lossynoPR_tvd_runs[i, :] = metric_tvd\n",
    "        lossynoPR_mmd_runs[i, :] = metric_mmd\n",
    "        lossynoPR_js_runs[i, :] = metric_js\n",
    "        \n",
    "        print('Training instance OK')\n",
    "        i += 1\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lossless case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train a QCBM without losses. Photon recycling is thus not necessary.\n",
    "\n",
    "We define it, and assign to it the same target distribution and same loss function as the first and second QCBMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossless = QCBM(parametrized_circuit=pqc, input_state=input_state, sample_count=sample_count, loss_parameter=0.0, pnr=pnr, \n",
    "                     use_samples_only = False, use_photon_recycling=False)\n",
    "\n",
    "bm_lossless.target_pdf = target_pdf\n",
    "bm_lossless.loss_fun = loss_fun\n",
    "bm_lossless.target_space = target_space\n",
    "\n",
    "# If using samples only\n",
    "#bm_lossless.target_samples = target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_lossless.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossless_loss_runs = np.zeros((run_count, it_count))\n",
    "lossless_tvd_runs = np.zeros((run_count, it_count))\n",
    "lossless_mmd_runs = np.zeros((run_count, it_count))\n",
    "lossless_js_runs = np.zeros((run_count, it_count))\n",
    "lossless_params_runs = np.zeros((run_count, len(bm_lossless.pqc.var_param_map)))\n",
    "\n",
    "# Set counter\n",
    "i = 0\n",
    "\n",
    "while i < run_count:\n",
    "    # If using saved init parameters:\n",
    "    init_params_lossy = init_params_runs[i]\n",
    "    bm_lossless.pqc.init_params(red_factor = 1, init_var_params = init_params_lossy)\n",
    "    \n",
    "    # If not:\n",
    "    #bm_lossless.pqc.init_params()\n",
    "    \n",
    "    print('Initialization OK')\n",
    "    \n",
    "    try:\n",
    "        loss_progress, params_progress, metric_tvd, metric_mmd, metric_js = bm_lossless.fit(opt_steps, it_count, silent=True)\n",
    "        lossless_loss_runs[i, :] = loss_progress\n",
    "        lossless_params_runs[i, :] = params_progress[-1]\n",
    "        \n",
    "        # Extra metrics saved for evaluation of the models:\n",
    "        lossless_tvd_runs[i, :] = metric_tvd\n",
    "        lossless_mmd_runs[i, :] = metric_mmd\n",
    "        lossless_js_runs[i, :] = metric_js\n",
    "        \n",
    "        print('Training instance OK')\n",
    "        i += 1\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can load previously saved results, we can analyze results by looking at plots of the various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "#path = ''\n",
    "#df_lossy_loss = pd.read_csv(path + \"lossy_loss.csv\")\n",
    "#df_lossynoPR_loss = pd.read_csv(path + \"lossynoPR_loss.csv\")\n",
    "#df_lossless_loss = pd.read_csv(path + \"lossless_loss.csv\")\n",
    "\n",
    "#lossy_loss_runs = df_lossy_loss.to_numpy()\n",
    "#lossynoPR_loss_runs = df_lossynoPR_loss.to_numpy()\n",
    "#lossless_loss_runs = df_lossless_loss.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging over the trainings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std over all simulation runs\n",
    "lossy_mean = lossy_loss_runs.mean(axis = 0)\n",
    "lossy_std = lossy_loss_runs.std(axis = 0)\n",
    "\n",
    "lossynoPR_mean = lossynoPR_loss_runs.mean(axis = 0)\n",
    "lossynoPR_std = lossynoPR_loss_runs.std(axis = 0)\n",
    "\n",
    "lossless_mean = lossless_loss_runs.mean(axis = 0)\n",
    "lossless_std = lossless_loss_runs.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking one iteration in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it_check = 0\n",
    "#lossy_mean = lossy_loss_runs[it_check]\n",
    "#lossynoPR_mean = lossynoPR_loss_runs[it_check]\n",
    "#lossless_mean = lossless_loss_runs[it_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting main loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies a left cutoff of the plot to accentuate the differences between ideal and noisy runs \n",
    "iteration_cutoff = 0\n",
    "\n",
    "x = np.arange(it_count)\n",
    "plt.plot(x[iteration_cutoff:], lossy_mean[iteration_cutoff:], label = 'Lossy with photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossy_mean - lossy_std)[iteration_cutoff:], (lossy_mean + lossy_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossynoPR_mean[iteration_cutoff:], label = 'Lossy without photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossynoPR_mean - lossynoPR_std)[iteration_cutoff:], (lossynoPR_mean + lossynoPR_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossless_mean[iteration_cutoff:], label = 'No losses')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossless_mean - lossless_std)[iteration_cutoff:], (lossless_mean + lossless_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parameters\n",
    "len(bm_lossless.pqc.var_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution sum to 1?\n",
    "sum(bm_lossless.pdf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution sum to 1?\n",
    "sum(bm_lossy.pdf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the distribution sum to 1?\n",
    "sum(bm_lossy_noPR.pdf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "path = 'results/results_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '/'\n",
    "os.mkdir(path)\n",
    "\n",
    "experiment_parameters  = {\"Ansatz\": [str(arch)],\n",
    "                          \"Input\": [str(input_state)],\n",
    "                          \"Nsamples\": [str(bm_lossy.sample_count)],\n",
    "                          \"Bins\": [str(bm_lossy.bin_count)],\n",
    "                          \"Loss\": [loss_name],\n",
    "                          \"Target\": [target_pdf_name],\n",
    "                          \"run_count\": [str(run_count)],\n",
    "                          \"it_count\": [str(it_count)],\n",
    "                          \"opt_steps\": [str(opt_steps)],\n",
    "                          \"sample_count\": [str(sample_count)],\n",
    "                          \"loss_parameter\": [str(loss_parameter)],\n",
    "                          \"one_param_per_interferometer\": [str(bm_lossy.pqc.one_param_per_interferometer)],\n",
    "                          \"same_params_in_var\": [str(bm_lossy.pqc.same_params_in_var)],\n",
    "                          \"PNR\": [str(pnr)]}\n",
    "\n",
    "df_experiment_parameters = pd.DataFrame(data = experiment_parameters)\n",
    "df_experiment_parameters.to_csv(path + \"experiment_parameters.csv\", index = False)\n",
    "\n",
    "df_init = pd.DataFrame(data = init_params_runs)\n",
    "df_init.to_csv(path + \"init.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossy_loss = pd.DataFrame(data = lossy_loss_runs)\n",
    "df_lossy_loss.to_csv(path + \"lossy_loss.csv\", index = False)\n",
    "\n",
    "df_lossy_params = pd.DataFrame(data = lossy_params_runs)\n",
    "df_lossy_params.to_csv(path + \"lossy_params.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossynoPR_loss = pd.DataFrame(data = lossynoPR_loss_runs)\n",
    "df_lossynoPR_loss.to_csv(path + \"lossynoPR_loss.csv\", index = False)\n",
    "\n",
    "df_lossynoPR_params = pd.DataFrame(data = lossynoPR_params_runs)\n",
    "df_lossynoPR_params.to_csv(path + \"lossynoPR_params.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossless_loss = pd.DataFrame(data = lossless_loss_runs)\n",
    "df_lossless_loss.to_csv(path + \"lossless_loss.csv\", index = False)\n",
    "\n",
    "df_lossless_params = pd.DataFrame(data = lossless_params_runs)\n",
    "df_lossless_params.to_csv(path + \"lossless_params.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at some extra metrics that we saved during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std over all simulation runs\n",
    "\n",
    "# TVD \n",
    "lossy_tvd_mean = lossy_tvd_runs.mean(axis = 0)\n",
    "lossy_tvd_std = lossy_tvd_runs.std(axis = 0)\n",
    "\n",
    "lossynoPR_tvd_mean = lossynoPR_tvd_runs.mean(axis = 0)\n",
    "lossynoPR_tvd_std = lossynoPR_tvd_runs.std(axis = 0)\n",
    "\n",
    "lossless_tvd_mean = lossless_tvd_runs.mean(axis = 0)\n",
    "lossless_tvd_std = lossless_tvd_runs.std(axis = 0)\n",
    "\n",
    "# MMD \n",
    "lossy_mmd_mean = lossy_mmd_runs.mean(axis = 0)\n",
    "lossy_mmd_std = lossy_mmd_runs.std(axis = 0)\n",
    "\n",
    "lossynoPR_mmd_mean = lossynoPR_mmd_runs.mean(axis = 0)\n",
    "lossynoPR_mmd_std = lossynoPR_mmd_runs.std(axis = 0)\n",
    "\n",
    "lossless_mmd_mean = lossless_mmd_runs.mean(axis = 0)\n",
    "lossless_mmd_std = lossless_mmd_runs.std(axis = 0)\n",
    "\n",
    "# JS distance\n",
    "lossy_js_mean = lossy_js_runs.mean(axis = 0)\n",
    "lossy_js_std = lossy_js_runs.std(axis = 0)\n",
    "\n",
    "lossynoPR_js_mean = lossynoPR_js_runs.mean(axis = 0)\n",
    "lossynoPR_js_std = lossynoPR_js_runs.std(axis = 0)\n",
    "\n",
    "lossless_js_mean = lossless_js_runs.mean(axis = 0)\n",
    "lossless_js_std = lossless_js_runs.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking one iteration in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it_check = 0\n",
    "#lossy_tvd_mean = lossy_tvd_runs[it_check]\n",
    "#lossynoPR_tvd_mean = lossynoPR_tvd_runs[it_check]\n",
    "#lossless_tvd_mean = lossless_tvd_runs[it_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the TVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies a left cutoff of the plot to accentuate the differences between ideal and noisy runs \n",
    "iteration_cutoff = 0\n",
    "\n",
    "x = np.arange(it_count)\n",
    "plt.plot(x[iteration_cutoff:], lossy_tvd_mean[iteration_cutoff:], label = 'Lossy with photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossy_tvd_mean - lossy_tvd_std)[iteration_cutoff:], (lossy_tvd_mean + lossy_tvd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossynoPR_tvd_mean[iteration_cutoff:], label = 'Lossy without photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossynoPR_tvd_mean - lossynoPR_tvd_std)[iteration_cutoff:], (lossynoPR_tvd_mean + lossynoPR_tvd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossless_tvd_mean[iteration_cutoff:], label = 'No losses')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossless_tvd_mean - lossless_tvd_std)[iteration_cutoff:], (lossless_tvd_mean + lossless_tvd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking one iteration in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it_check = 0\n",
    "#lossy_mmd_mean = lossy_mmd_runs[it_check]\n",
    "#lossynoPR_mmd_mean = lossynoPR_mmd_runs[it_check]\n",
    "#lossless_mmd_mean = lossless_mmd_runs[it_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the MMD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies a left cutoff of the plot to accentuate the differences between ideal and noisy runs \n",
    "iteration_cutoff = 0\n",
    "\n",
    "x = np.arange(it_count)\n",
    "plt.plot(x[iteration_cutoff:], lossy_mmd_mean[iteration_cutoff:], label = 'Lossy with photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossy_mmd_mean - lossy_mmd_std)[iteration_cutoff:], (lossy_mmd_mean + lossy_mmd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossynoPR_mmd_mean[iteration_cutoff:], label = 'Lossy without photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossynoPR_mmd_mean - lossynoPR_mmd_std)[iteration_cutoff:], (lossynoPR_mmd_mean + lossynoPR_mmd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossless_mmd_mean[iteration_cutoff:], label = 'No losses')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossless_mmd_mean - lossless_mmd_std)[iteration_cutoff:], (lossless_mmd_mean + lossless_mmd_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking one iteration in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it_check = 0\n",
    "#lossy_js_mean = lossy_js_runs[it_check]\n",
    "#lossynoPR_js_mean = lossynoPR_js_runs[it_check]\n",
    "#lossless_js_mean = lossless_js_runs[it_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the Jensen Shannon divergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies a left cutoff of the plot to accentuate the differences between ideal and noisy runs \n",
    "iteration_cutoff = 0\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "x = np.arange(it_count)\n",
    "plt.plot(x[iteration_cutoff:], lossy_js_mean[iteration_cutoff:], label = 'Lossy with photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossy_js_mean - lossy_js_std)[iteration_cutoff:], (lossy_js_mean + lossy_js_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossynoPR_js_mean[iteration_cutoff:], label = 'Lossy without photon recycling')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossynoPR_js_mean - lossynoPR_js_std)[iteration_cutoff:], (lossynoPR_js_mean + lossynoPR_js_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "plt.plot(x[iteration_cutoff:], lossless_js_mean[iteration_cutoff:], label = 'No losses')\n",
    "plt.fill_between(x[iteration_cutoff:], (lossless_js_mean - lossless_js_std)[iteration_cutoff:], (lossless_js_mean + lossless_js_std)[iteration_cutoff:], alpha=0.2)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save those metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossy_tvd = pd.DataFrame(data = lossy_tvd_runs)\n",
    "df_lossy_tvd.to_csv(path + \"lossy_tvd.csv\", index = False)\n",
    "\n",
    "df_lossless_tvd = pd.DataFrame(data = lossless_tvd_runs)\n",
    "df_lossless_tvd.to_csv(path + \"lossless_tvd.csv\", index = False)\n",
    "\n",
    "df_lossynoPR_tvd = pd.DataFrame(data = lossynoPR_tvd_runs)\n",
    "df_lossynoPR_tvd.to_csv(path + \"lossynoPR_tvd.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossy_mmd = pd.DataFrame(data = lossy_mmd_runs)\n",
    "df_lossy_mmd.to_csv(path + \"lossy_mmd.csv\", index = False)\n",
    "\n",
    "df_lossless_mmd = pd.DataFrame(data = lossless_mmd_runs)\n",
    "df_lossless_mmd.to_csv(path + \"lossless_mmd.csv\", index = False)\n",
    "\n",
    "df_lossynoPR_mmd = pd.DataFrame(data = lossynoPR_mmd_runs)\n",
    "df_lossynoPR_mmd.to_csv(path + \"lossynoPR_mmd.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossy_js = pd.DataFrame(data = lossy_js_runs)\n",
    "df_lossy_js.to_csv(path + \"lossy_js.csv\", index = False)\n",
    "\n",
    "df_lossless_js = pd.DataFrame(data = lossless_js_runs)\n",
    "df_lossless_js.to_csv(path + \"lossless_js.csv\", index = False)\n",
    "\n",
    "df_lossynoPR_js = pd.DataFrame(data = lossynoPR_js_runs)\n",
    "df_lossynoPR_js.to_csv(path + \"lossynoPR_js.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa9f1ff1a1ae38a23f5d9c1f106e92a8afce6ae093d0df970bb82e4127674958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
